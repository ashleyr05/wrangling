{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
      "metadata": {
        "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
      },
      "source": [
        "# Assignment: Data Wrangling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5735a4d4-8be8-433a-a351-70eb8002e632",
      "metadata": {
        "id": "5735a4d4-8be8-433a-a351-70eb8002e632"
      },
      "source": [
        "**Q1.** Open the \"tidy_data.pdf\" document in the repo, which is a paper called Tidy Data by Hadley Wickham.\n",
        "\n",
        "  1. Read the abstract. What is this paper about?\n",
        "    \n",
        "    This paper is about how to make data cleanign as easy and effective as possible. Specifically this paper is talking about data tidying. This technique makes it easier to make messy datasets nicer because there is a small amount of tools that need to be used. There is also a case study in this paper showing how this method is more effective.\n",
        "\n",
        "  2. Read the introduction. What is the \"tidy data standard\" intended to accomplish?\n",
        "\n",
        "    The tidy data standard is intended to accomplish initial analysis of the data in order to determine data analysis tools that will work well for the data.\n",
        "\n",
        "  3. Read the intro to section 2. What does this sentence mean: \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\" What does this sentence mean: \"For a given dataset, it’s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\"\n",
        "\n",
        "    The sentence, \"Like families, tidy datasets are all alike but every messy dataset is messy in its own way.\", means that no dataset is the same, similar to how families have different things that are going on in their lives. Also, that no family or tidy dataset is perfect. Families also have a general structure similar to how tidy datasets have a typical structure. The sentence, \"For a given dataset, it’s usually easy to figure out what are observations and what are variables, but it is surprisingly difficult to precisely define variables and observations in general.\", means that it is easy to identify what are the variables/observations are in a dataset. However, it is difficult to define what those observations/variables mean in the context of the dataset.\n",
        "\n",
        "  4. Read Section 2.2. How does Wickham define values, variables, and observations?\n",
        "\n",
        "    Wickham defines values as usually either numbers (if quantitative) or strings (if qualitative) that are in a dataset. The author defines variables as something that contains all values that measure the same underlying attribute (like height, temperature, duration) across units. Every value belongs to a variable and observation. Observations are defined as something that contains all values measured on the same unit (like a person, or a day, or a race) across attributes.\n",
        "\n",
        "  5. How is \"Tidy Data\" defined in section 2.3?\n",
        "\n",
        "    Tidy Data is defined as a dataset where each variable forms a column, each observation forms a row, and each type of observational unti forms a table.\n",
        "\n",
        "  6. Read the intro to Section 3 and Section 3.1. What are the 5 most common problems with messy datasets? Why are the data in Table 4 messy? What is \"melting\" a dataset?\n",
        "\n",
        "    The five most common problems with messy datasets are column headers are actually values not variable names, multiple variables are stored in one column, variables are stored in both rows and columns, multiple types of observational units are stored in the same table, and a single observational unit is stored in multiple tables. Table 4 is messy because the columns need to be turned into rows, which is what \"metling\" a dataset is. The columns in Table 4 are variables, which makes it messy.\n",
        "\n",
        "  7. Why, specifically, is table 11 messy but table 12 tidy and \"molten\"?\n",
        "\n",
        "    Table 11 is messy because it has variables stored in both rows and columns. It has variables in individual columns (id, year, month) in columns (day, d1–d31) and in rows (tmin, tmax) (minimum and maximum temperature). Also, the months with less than 31 days have missing values for the last days of the month. Table 12 is tidy and molten because Table 12 is the melted version of Table 11, and it is now tidy. It was melted by melting the colvars id, year, month and the column that contains variable names, element.\n",
        "\n",
        "  8. Read Section 6. What is the \"chicken-and-egg\" problem with focusing on tidy data? What does Wickham hope happens in the future with further work on the subject of data wrangling?\n",
        "\n",
        "    The \"chicken-and-egg\" problem is if tidy data is only as useful as the tools that work with it, then tidy tools will be strongly linked to tidy data. Wickham hopes that other frameworks are developed that make the following data cleaning processes much easier: parsing dates and numbers, identifying missing values, correcting character encodings (for international data), matching similar but not identical values (created by typos), verifying experimental design, and filling in structural missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072",
      "metadata": {
        "id": "da879ea7-8aac-48a3-b6c2-daea56d2e072"
      },
      "source": [
        "**Q2.** This question provides some practice cleaning variables which have common problems.\n",
        "1. Numeric variable: For `./data/airbnb_hw.csv`, clean the `Price` variable as well as you can, and explain the choices you make. How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "2. Categorical variable: For the `./data/sharks.csv` data covered in the lecture, clean the \"Type\" variable as well as you can, and explain the choices you make.\n",
        "3. Dummy variable: For the pretrial data covered in the lecture, clean the `WhetherDefendantWasReleasedPretrial` variable as well as you can, and, in particular, replace missing values with `np.nan`.\n",
        "4. Missing values, not at random: For the pretrial data covered in the lecture, clean the `ImposedSentenceAllChargeInContactEvent` variable as well as you can, and explain the choices you make. (Hint: Look at the `SentenceTypeAllChargesAtConvictionInContactEvent` variable.)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/DS3001/wrangling"
      ],
      "metadata": {
        "id": "eb4_zblaF53i",
        "outputId": "a3f69e6f-3060-4b9d-9e20-2788e8476578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eb4_zblaF53i",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'wrangling'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (40/40), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 83 (delta 31), reused 11 (delta 11), pack-reused 43\u001b[K\n",
            "Receiving objects: 100% (83/83), 10.85 MiB | 26.08 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Numeric variable: For ./data/airbnb_hw.csv, clean the Price variable as well as you can, and explain the choices you make.\n",
        "# How many missing values do you end up with? (Hint: What happens to the formatting when a price goes over 999 dollars, say from 675 to 1,112?)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "air_df = pd.read_csv('/content/wrangling/assignment/data/airbnb_hw.csv',low_memory=False) # reading the airbnb CSV into a dataframe using Pandas"
      ],
      "metadata": {
        "id": "0-FgTLuyGzJk"
      },
      "id": "0-FgTLuyGzJk",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price = air_df['Price'] # setting the 'Price' column to a variable\n",
        "price.unique() # displaying all the values in price\n",
        "price.value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "pr7M62A4IBX8",
        "outputId": "d9bbc865-6346-4d99-8700-de6d53992909",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pr7M62A4IBX8",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150      1481\n",
              "100      1207\n",
              "200      1059\n",
              "125       889\n",
              "75        873\n",
              "         ... \n",
              "840         1\n",
              "306         1\n",
              "2,695       1\n",
              "2,520       1\n",
              "291         1\n",
              "Name: Price, Length: 511, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price = price.str.replace(',', '')\n",
        "  # I replaced the commas in the numbers because it was registering the data as string when they have commas,\n",
        "  # but I want them to be recognized as integers. The commas can be removed by using the str.replace() method.\n",
        "price.unique() # displaying all the values in price"
      ],
      "metadata": {
        "id": "h0UZg-A3KwXH",
        "outputId": "e5c786de-5ff0-4720-8624-cb41494738c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "h0UZg-A3KwXH",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['145', '37', '28', '199', '549', '149', '250', '90', '270', '290',\n",
              "       '170', '59', '49', '68', '285', '75', '100', '150', '700', '125',\n",
              "       '175', '40', '89', '95', '99', '499', '120', '79', '110', '180',\n",
              "       '143', '230', '350', '135', '85', '60', '70', '55', '44', '200',\n",
              "       '165', '115', '74', '84', '129', '50', '185', '80', '190', '140',\n",
              "       '45', '65', '225', '600', '109', '1990', '73', '240', '72', '105',\n",
              "       '155', '160', '42', '132', '117', '295', '280', '159', '107', '69',\n",
              "       '239', '220', '399', '130', '375', '585', '275', '139', '260',\n",
              "       '35', '133', '300', '289', '179', '98', '195', '29', '27', '39',\n",
              "       '249', '192', '142', '169', '1000', '131', '138', '113', '122',\n",
              "       '329', '101', '475', '238', '272', '308', '126', '235', '315',\n",
              "       '248', '128', '56', '207', '450', '215', '210', '385', '445',\n",
              "       '136', '247', '118', '77', '76', '92', '198', '205', '299', '222',\n",
              "       '245', '104', '153', '349', '114', '320', '292', '226', '420',\n",
              "       '500', '325', '307', '78', '265', '108', '123', '189', '32', '58',\n",
              "       '86', '219', '800', '335', '63', '229', '425', '67', '87', '1200',\n",
              "       '158', '650', '234', '310', '695', '400', '166', '119', '62',\n",
              "       '168', '340', '479', '43', '395', '144', '52', '47', '529', '187',\n",
              "       '209', '233', '82', '269', '163', '172', '305', '156', '550',\n",
              "       '435', '137', '124', '48', '279', '330', '5000', '134', '378',\n",
              "       '97', '277', '64', '193', '147', '186', '264', '30', '3000', '112',\n",
              "       '94', '379', '57', '415', '236', '410', '214', '88', '66', '71',\n",
              "       '171', '157', '545', '1500', '83', '96', '1800', '81', '188',\n",
              "       '380', '255', '505', '54', '33', '174', '93', '740', '640', '1300',\n",
              "       '440', '599', '357', '1239', '495', '127', '5999', '178', '348',\n",
              "       '152', '242', '183', '253', '750', '259', '365', '273', '197',\n",
              "       '397', '103', '389', '355', '559', '38', '203', '999', '141',\n",
              "       '162', '333', '698', '46', '360', '895', '10', '41', '206', '281',\n",
              "       '449', '388', '212', '102', '201', '2750', '4750', '432', '675',\n",
              "       '167', '390', '298', '339', '194', '302', '211', '595', '191',\n",
              "       '53', '361', '480', '8000', '4500', '459', '997', '345', '216',\n",
              "       '218', '111', '735', '276', '91', '490', '850', '398', '36', '775',\n",
              "       '267', '625', '336', '2500', '176', '725', '3750', '469', '106',\n",
              "       '460', '287', '575', '227', '263', '25', '228', '208', '177',\n",
              "       '880', '148', '116', '685', '470', '217', '164', '61', '645',\n",
              "       '699', '405', '252', '319', '268', '419', '343', '525', '311',\n",
              "       '840', '154', '294', '950', '409', '184', '257', '204', '241',\n",
              "       '2000', '412', '121', '288', '196', '900', '647', '524', '1750',\n",
              "       '309', '510', '1495', '1700', '799', '383', '372', '492', '327',\n",
              "       '1999', '656', '224', '173', '875', '1170', '795', '690', '146',\n",
              "       '465', '1100', '151', '274', '429', '825', '282', '256', '1111',\n",
              "       '620', '271', '161', '51', '855', '579', '1174', '430', '20',\n",
              "       '899', '649', '485', '181', '455', '4000', '243', '342', '590',\n",
              "       '560', '374', '437', '232', '359', '985', '31', '244', '254',\n",
              "       '723', '237', '428', '370', '34', '1400', '580', '2520', '221',\n",
              "       '749', '1600', '2695', '306', '202', '680', '570', '520', '223',\n",
              "       '2295', '213', '1065', '346', '24', '286', '296', '266', '26',\n",
              "       '995', '1368', '393', '182', '635', '258', '780', '589', '347',\n",
              "       '1250', '1350', '446', '3200', '1050', '1650', '1550', '975',\n",
              "       '323', '6500', '2499', '1850', '2250', '715', '461', '540', '356',\n",
              "       '439', '384', '569', '1900', '22', '785', '626', '830', '318',\n",
              "       '444', '321', '401', '1499', '888', '369', '770', '386', '366',\n",
              "       '344', '630', '313', '597', '262', '509', '10000', '278', '312',\n",
              "       '789', '1195', '422', '21', '765', '3500', '945', '326', '3100',\n",
              "       '2486', '3390', '1356', '2599', '472', '454', '328', '396', '291'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "price = pd.to_numeric(price, errors='coerce')\n",
        "# The 'Price' variable is a numeric variable, but the data currently is stored as the object datatype.\n",
        "# To change the 'Price' data to numeric I used the pd.to_numeric() function.\n",
        "price.unique() # displaying all the values in price"
      ],
      "metadata": {
        "id": "lPBwjDHrMgyJ",
        "outputId": "ecb6c769-9165-4623-bbea-b89b28276259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "lPBwjDHrMgyJ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  145,    37,    28,   199,   549,   149,   250,    90,   270,\n",
              "         290,   170,    59,    49,    68,   285,    75,   100,   150,\n",
              "         700,   125,   175,    40,    89,    95,    99,   499,   120,\n",
              "          79,   110,   180,   143,   230,   350,   135,    85,    60,\n",
              "          70,    55,    44,   200,   165,   115,    74,    84,   129,\n",
              "          50,   185,    80,   190,   140,    45,    65,   225,   600,\n",
              "         109,  1990,    73,   240,    72,   105,   155,   160,    42,\n",
              "         132,   117,   295,   280,   159,   107,    69,   239,   220,\n",
              "         399,   130,   375,   585,   275,   139,   260,    35,   133,\n",
              "         300,   289,   179,    98,   195,    29,    27,    39,   249,\n",
              "         192,   142,   169,  1000,   131,   138,   113,   122,   329,\n",
              "         101,   475,   238,   272,   308,   126,   235,   315,   248,\n",
              "         128,    56,   207,   450,   215,   210,   385,   445,   136,\n",
              "         247,   118,    77,    76,    92,   198,   205,   299,   222,\n",
              "         245,   104,   153,   349,   114,   320,   292,   226,   420,\n",
              "         500,   325,   307,    78,   265,   108,   123,   189,    32,\n",
              "          58,    86,   219,   800,   335,    63,   229,   425,    67,\n",
              "          87,  1200,   158,   650,   234,   310,   695,   400,   166,\n",
              "         119,    62,   168,   340,   479,    43,   395,   144,    52,\n",
              "          47,   529,   187,   209,   233,    82,   269,   163,   172,\n",
              "         305,   156,   550,   435,   137,   124,    48,   279,   330,\n",
              "        5000,   134,   378,    97,   277,    64,   193,   147,   186,\n",
              "         264,    30,  3000,   112,    94,   379,    57,   415,   236,\n",
              "         410,   214,    88,    66,    71,   171,   157,   545,  1500,\n",
              "          83,    96,  1800,    81,   188,   380,   255,   505,    54,\n",
              "          33,   174,    93,   740,   640,  1300,   440,   599,   357,\n",
              "        1239,   495,   127,  5999,   178,   348,   152,   242,   183,\n",
              "         253,   750,   259,   365,   273,   197,   397,   103,   389,\n",
              "         355,   559,    38,   203,   999,   141,   162,   333,   698,\n",
              "          46,   360,   895,    10,    41,   206,   281,   449,   388,\n",
              "         212,   102,   201,  2750,  4750,   432,   675,   167,   390,\n",
              "         298,   339,   194,   302,   211,   595,   191,    53,   361,\n",
              "         480,  8000,  4500,   459,   997,   345,   216,   218,   111,\n",
              "         735,   276,    91,   490,   850,   398,    36,   775,   267,\n",
              "         625,   336,  2500,   176,   725,  3750,   469,   106,   460,\n",
              "         287,   575,   227,   263,    25,   228,   208,   177,   880,\n",
              "         148,   116,   685,   470,   217,   164,    61,   645,   699,\n",
              "         405,   252,   319,   268,   419,   343,   525,   311,   840,\n",
              "         154,   294,   950,   409,   184,   257,   204,   241,  2000,\n",
              "         412,   121,   288,   196,   900,   647,   524,  1750,   309,\n",
              "         510,  1495,  1700,   799,   383,   372,   492,   327,  1999,\n",
              "         656,   224,   173,   875,  1170,   795,   690,   146,   465,\n",
              "        1100,   151,   274,   429,   825,   282,   256,  1111,   620,\n",
              "         271,   161,    51,   855,   579,  1174,   430,    20,   899,\n",
              "         649,   485,   181,   455,  4000,   243,   342,   590,   560,\n",
              "         374,   437,   232,   359,   985,    31,   244,   254,   723,\n",
              "         237,   428,   370,    34,  1400,   580,  2520,   221,   749,\n",
              "        1600,  2695,   306,   202,   680,   570,   520,   223,  2295,\n",
              "         213,  1065,   346,    24,   286,   296,   266,    26,   995,\n",
              "        1368,   393,   182,   635,   258,   780,   589,   347,  1250,\n",
              "        1350,   446,  3200,  1050,  1650,  1550,   975,   323,  6500,\n",
              "        2499,  1850,  2250,   715,   461,   540,   356,   439,   384,\n",
              "         569,  1900,    22,   785,   626,   830,   318,   444,   321,\n",
              "         401,  1499,   888,   369,   770,   386,   366,   344,   630,\n",
              "         313,   597,   262,   509, 10000,   278,   312,   789,  1195,\n",
              "         422,    21,   765,  3500,   945,   326,  3100,  2486,  3390,\n",
              "        1356,  2599,   472,   454,   328,   396,   291])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total missing: ', sum(price.isnull())) # displaying the calculated sum of all of the missing values in price"
      ],
      "metadata": {
        "id": "NDj41oFCOUXi",
        "outputId": "f25947af-b9e1-4215-8ba9-9fcb70209319",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "NDj41oFCOUXi",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total missing:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Categorical variable: For the ./data/sharks.csv data covered in the lecture, clean the \"Type\" variable as well as you can, and\n",
        "# explain the choices you make.\n",
        "\n",
        "sdf = pd.read_csv('/content/wrangling/assignment/data/sharks.csv',low_memory=False) # reading the sharks CSV into a dataframe using Pandas"
      ],
      "metadata": {
        "id": "_-vCl5nXUP_2"
      },
      "id": "_-vCl5nXUP_2",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attack_type = sdf['Type'] # setting the 'Type' column to a variable\n",
        "attack_type.unique() # displaying all the values in attack_type\n",
        "attack_type.value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "3j3w-RuEUg0d",
        "outputId": "3932539b-ea95-4b6a-b16a-8dbe2c77c782",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "3j3w-RuEUg0d",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked             4716\n",
              "Provoked                593\n",
              "Invalid                 552\n",
              "Sea Disaster            239\n",
              "Watercraft              142\n",
              "Boat                    109\n",
              "Boating                  92\n",
              "Questionable             10\n",
              "Unconfirmed               1\n",
              "Unverified                1\n",
              "Under investigation       1\n",
              "Boatomg                   1\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_type = attack_type.replace(['Sea Disaster', 'Boat','Boating','Boatomg'],'Watercraft')\n",
        "  # I replaced all of the watercraft-related attack types to be named 'Watercraft' in order to clean the data so there wasn't redundancy in\n",
        "  # attack types. I did this using the replace() method.\n",
        "attack_type.value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "vrChCs8LU8XU",
        "outputId": "a6f21758-9236-404c-a273-56fb7f91f73d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vrChCs8LU8XU",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked             4716\n",
              "Provoked                593\n",
              "Watercraft              583\n",
              "Invalid                 552\n",
              "Questionable             10\n",
              "Unconfirmed               1\n",
              "Unverified                1\n",
              "Under investigation       1\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_type = attack_type.replace(['Invalid', 'Questionable','Unconfirmed','Unverified','Under investigation'], np.nan)\n",
        "  # I replaced all of the missing data with np.nan, which means 'Not-a-number' since those values individually are not valuable data.\n",
        "  # However, all of them collectively are important for analysis and to make note of in the data because they are the missing data values.\n",
        "  # We can combine them so there aren't a redundant amount of missing value name and store them as NaN values.\n",
        "attack_type.value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "8LVDZsGOVrXS",
        "outputId": "bc307956-049c-44c0-fb64-9bf4b1938192",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8LVDZsGOVrXS",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked    4716\n",
              "Provoked       593\n",
              "Watercraft     583\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sdf['Type'] = attack_type # Replace the 'Type' variable with the cleaned version\n",
        "del attack_type # Destroy the temporary attack_type vector\n",
        "\n",
        "sdf['Type'].value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "EsbbKm7IXk9B",
        "outputId": "5d51d90b-d79e-46ef-cf44-6a7116dc062c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EsbbKm7IXk9B",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unprovoked    4716\n",
              "Provoked       593\n",
              "Watercraft     583\n",
              "Name: Type, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Dummy variable: For the pretrial data covered in the lecture, clean the WhetherDefendantWasReleasedPretrial variable as well as you can,\n",
        "# and, in particular, replace missing values with np.nan.\n",
        "\n",
        "url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv' # storing the url for the Justice Data\n",
        "jdf = pd.read_csv(url,low_memory=False) # Pandas downloads and loads the .csv file from the url"
      ],
      "metadata": {
        "id": "7PvRIerFYGlv"
      },
      "id": "7PvRIerFYGlv",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "released = jdf['WhetherDefendantWasReleasedPretrial'] # setting the 'WhetherDefendantWasReleasedPretrial' column to a variable\n",
        "released.value_counts() # displaying the amount of times each value appears"
      ],
      "metadata": {
        "id": "bdJZFZU02Dls",
        "outputId": "c5a7d989-4dc3-43c0-ef44-08d35fbd7668",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "bdJZFZU02Dls",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    19154\n",
              "0     3801\n",
              "9       31\n",
              "Name: WhetherDefendantWasReleasedPretrial, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "released = released.replace(9, np.nan)\n",
        "# I replaced all of the missing data, or the '9' values, with np.nan, which means 'Not-a-number' since those values individually are not valuable data.\n",
        "  # However, all of them collectively are important for analysis and to make note of in the data because they are the missing data values.\n",
        "  # We can combine them so there aren't a redundant amount of missing value name and store them as NaN values.\n",
        "released.value_counts() # displaying the amount of times each value appears\n",
        "jdf['WhetherDefendantWasReleasedPretrial'] = released # Replace the 'WhetherDefendantWasReleasedPretrial' variable with the cleaned version\n",
        "del released # Destroy the temporary released vector"
      ],
      "metadata": {
        "id": "U-3x-ZRf2lce"
      },
      "id": "U-3x-ZRf2lce",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Missing values, not at random: For the pretrial data covered in the lecture,\n",
        "# clean the ImposedSentenceAllChargeInContactEvent variable as well as you can, and explain the choices you make.\n",
        "# (Hint: Look at the SentenceTypeAllChargesAtConvictionInContactEvent variable.)\n",
        "\n",
        "sentence = jdf['ImposedSentenceAllChargeInContactEvent'] # setting the 'ImposedSentenceAllChargeInContactEvent' column to a variable\n",
        "print(sentence.value_counts(),'\\n') # displaying the amount of times each value appears\n",
        "print(sentence.unique(), '\\n') # displaying the unique values in the ImposedSentenceAllChargeInContactEvent column\n",
        "sentence = pd.to_numeric(sentence,errors='coerce')\n",
        "# The 'ImposedSentenceAllChargeInContactEvent' variable is a numeric variable, but the data currently has some ' ' values so I want to make it numeric.\n",
        "# To change the 'ImposedSentenceAllChargeInContactEvent' data to numeric I used the pd.to_numeric() function."
      ],
      "metadata": {
        "id": "4TQ6xyDn4Q_V",
        "outputId": "d5b8a4fa-6cb6-48e2-c906-89d3fb53ef71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "4TQ6xyDn4Q_V",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    9053\n",
            "0                   4953\n",
            "12                  1404\n",
            ".985626283367556    1051\n",
            "6                    809\n",
            "                    ... \n",
            "49.9712525667351       1\n",
            "57.0349075975359       1\n",
            "79.9260780287474       1\n",
            "42.1642710472279       1\n",
            "1.6570841889117        1\n",
            "Name: ImposedSentenceAllChargeInContactEvent, Length: 484, dtype: int64 \n",
            "\n",
            "[' ' '60' '12' '.985626283367556' '36' '6' '24' '5.91375770020534' '120'\n",
            " '72' '11.9917864476386' '0' '2.95687885010267' '84' '108' '300' '240'\n",
            " '180' '4' '96' '2' '54' '.328542094455852' '44' '5' '115' '132' '48'\n",
            " '258' '34' '76' '.164271047227926' '.131416837782341' '111' '9' '3'\n",
            " '1.97125256673511' '36.9856262833676' '.0657084188911704'\n",
            " '35.4928131416838' '106.492813141684' '8' '35' '18.3141683778234' '480'\n",
            " '32' '93' '234' '732' '1.16427104722793' '4.6570841889117' '21' '7'\n",
            " '4.49281314168378' '18' '600' '43.1642710472279' '179' '52' '30' '20'\n",
            " '192' '702' '14' '55' '53' '11.9055441478439' '114' '35.0061601642711'\n",
            " '68' '.657084188911704' '46.6242299794661' '102' '65' '200' '57'\n",
            " '24.3285420944559' '12.1642710472279' '117' '81.4928131416838'\n",
            " '22.4928131416838' '1980' '3.6570841889117' '56' '10' '2.79260780287474'\n",
            " '1' '47' '22' '1500' '40' '284' '11' '118' '42' '162' '156'\n",
            " '47.2956878850103' '105' '51' '246' '29' '75' '324' '360'\n",
            " '34.4804928131417' '120.328542094456' '59.9260780287474' '66'\n",
            " '59.9917864476386' '660' '51.1642710472279' '14.9568788501027'\n",
            " '3.98562628336756' '78' '228' '1.47843942505133' '62' '4.8' '86' '168'\n",
            " '23' '33' '48.0328542094456' '720' '348' '1200' '27' '49' '87' '420' '63'\n",
            " '79.9260780287474' '57.0349075975359' '49.9712525667351'\n",
            " '59.4928131416838' '17' '238.492813141684' '60.9856262833676' '126' '45'\n",
            " '158' '216' '227' '42.9568788501027' '445' '70.952772073922' '516'\n",
            " '177.82135523614' '1752' '90' '1080' '141' '4.82956878850103' '230' '31'\n",
            " '2208' '52.5133470225873' '69' '26' '33.4928131416838' '140' '131' '344'\n",
            " '219' '101' '71' '59' '58' '120.197125256674' '67' '35.4004106776181'\n",
            " '3.28542094455852' '40.1642710472279' '91' '1.7741273100616' '155'\n",
            " '34.4928131416838' '81' '92.3285420944559' '3.5482546201232' '207' '74'\n",
            " '518' '28' '8.95687885010267' '237' '404.673511293634' '18.1642710472279'\n",
            " '10.7433264887064' '551' '39' '15' '124' '43' '176' '19.4928131416838'\n",
            " '482' '129' '88' '46' '45.8542094455852' '128.628336755647'\n",
            " '136.492813141684' '108.328542094456' '50' '363.663244353183' '288' '250'\n",
            " '107' '81.0225872689938' '444' '205' '10.6570841889117' '19'\n",
            " '66.9856262833676' '38.4928131416838' '264' '276' '173' '222' '144' '294'\n",
            " '336' '431' '450' '73' '99.3285420944559' '128' '30.8069815195072'\n",
            " '31.5256673511294' '127' '202' '55.3285420944559' '89' '242'\n",
            " '1.31416837782341' '1029' '.788501026694045' '194.858316221766' '399'\n",
            " '39.6570841889117' '56.95687885' '198' '120.985626283368'\n",
            " '47.6570841889117' '148' '6.8993839835729' '65.3285420944559'\n",
            " '5.95277207392197' '.0985626283367557' '3.32854209445585'\n",
            " '3.94250513347023' '12.9856262833676' '6.98562628336756'\n",
            " '13.1498973305955' '15.1642710472279' '17.1971252566735'\n",
            " '17.9137577002053' '104' '212' '24.6570841889117' '72.6570841889117'\n",
            " '2.98562628336756' '144.985626283368' '31.9712525667351' '183'\n",
            " '4.98562628336756' '11.8213552361396' '252' '12.394250513347'\n",
            " '42.4928131416838' '10.1642710472279' '11.1642710472279'\n",
            " '5.49281314168378' '59.6632443531827' '12.3285420944559'\n",
            " '48.9856262833676' '240.985626283368' '2.6570841889117' '540'\n",
            " '2.97125256673511' '6.32854209445585' '23.6632443531828'\n",
            " '133.657084188912' '35.3285420944559' '456' '103' '1.72279260780287'\n",
            " '12.6570841889117' '11.6570841889117' '60.3285420944559'\n",
            " '3.78850102669405' '576' '2.13141683778234' '492' '14.9856262833676'\n",
            " '24.9856262833676' '61.9712525667351' '5.6570841889117' '16'\n",
            " '42.1642710472279' '.492813141683778' '138' '13.3141683778234'\n",
            " '11.8932238193018' '5.32854209445585' '95' '62.6570841889117'\n",
            " '3.08829568788501' '11.8275154004107' '1.64271047227926'\n",
            " '47.9917864476386' '4.27104722792608' '8.32854209445585'\n",
            " '3.31416837782341' '70' '77' '1.09856262833676' '48.1642710472279'\n",
            " '27.4928131416838' '6.93839835728953' '1011' '.68993839835729'\n",
            " '1.1170431211499' '1.49281314168378' '4.16427104722793'\n",
            " '1.19712525667351' '4.07392197125257' '188' '11.3285420944559'\n",
            " '.0328542094455852' '432' '11.952772073922' '36.4928131416838'\n",
            " '23.9835728952772' '9.98562628336756' '98' '36.3285420944559' '112'\n",
            " '.394250513347023' '13' '.262833675564682' '13.7987679671458'\n",
            " '5.8870636550308' '354' '5.91991786447639' '24.1642710472279'\n",
            " '62.95687885' '4.59958932238193' '123' '2.32854209445585'\n",
            " '23.9240246406571' '204' '197' '174' '16.1498973305955' '840' '440'\n",
            " '98.95687885' '17.952772073922' '63.9425051334702' '60.1314168377823'\n",
            " '12.1314168377823' '172.952772073922' '.197125256673511'\n",
            " '138.164271047228' '4.92813141683778' '.919917864476386'\n",
            " '18.9856262833676' '6.6570841889117' '2.85420944558522'\n",
            " '8.91375770020534' '146' '12.4928131416838' '.558521560574949'\n",
            " '.722792607802875' '5.82135523613963' '84.9856262833676'\n",
            " '6.16427104722793' '15.9856262833676' '64.5585215605749'\n",
            " '38.299794661191' '11.958932238193' '3.1211498973306' '126.328542094456'\n",
            " '5.16427104722793' '64' '42.6570841889117' '312' '19.9712525667351'\n",
            " '82.3285420944559' '23.9712525667351' '17.6242299794661'\n",
            " '121.971252566735' '59.6550308008214' '1.32854209445585'\n",
            " '7.97125256673511' '1.91991786447639' '.525667351129363'\n",
            " '9.32854209445585' '42.9856262833676' '41.9137577002053'\n",
            " '72.9856262833676' '12.4784394250513' '5.19096509240246' '473'\n",
            " '16.6570841889117' '109' '86.3285420944559' '41' '1.90554414784394'\n",
            " '94.1642710472279' '302' '4.39425051334702' '10.8213552361396'\n",
            " '18.3285420944559' '154' '83' '110.956878850103' '226' '96.0328542094456'\n",
            " '4.82135523613963' '30.3285420944559' '37.9712525667351'\n",
            " '50.4640657084189' '286' '99' '99.4928131416838' '2.6611909650924'\n",
            " '70.9712525667351' '13.9712525667351' '23.6570841889117'\n",
            " '.459958932238193' '132.492813141684' '283' '49.3141683778234'\n",
            " '27.9856262833676' '38' '7.6570841889117' '83.6550308008214'\n",
            " '10.9199178644764' '162.328542094456' '37' '132.328542094456'\n",
            " '35.952772073922' '165' '10.9856262833676' '20.1642710472279'\n",
            " '2.59137577002053' '175' '180.985626283368' '10.3285420944559'\n",
            " '36.1642710472279' '120.657084188912' '232' '152' '8.98562628336756'\n",
            " '167' '11.0657084188912' '11.2032854209446' '5.19712525667351'\n",
            " '3.16427104722793' '60.1642710472279' '1.18275154004107'\n",
            " '21.1642710472279' '2.19712525667351' '4.19712525667351'\n",
            " '2.62833675564682' '119.952772073922' '119.958932238193'\n",
            " '9.49281314168378' '5.25667351129363' '15.3285420944559'\n",
            " '2.82135523613963' '192.985626283368' '48.6570841889117'\n",
            " '5.95687885010267' '2.29979466119097' '960' '2.36550308008214' '116'\n",
            " '19.5133470225873' '1.6570841889117'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_nan = sentence.isnull() # Create a missing dummy\n",
        "print(np.sum(sentence_nan),'\\n') # displaying the calculated sum of all of the missing values in sentence_nan"
      ],
      "metadata": {
        "id": "y9Mk26Wh9l4H",
        "outputId": "11ddd4ee-a42a-423b-fe75-2df24cf473f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "y9Mk26Wh9l4H",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9053 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_type = jdf['SentenceTypeAllChargesAtConvictionInContactEvent'] # setting the 'SentenceTypeAllChargesAtConvictionInContactEvent' column to a variable\n",
        "print(pd.crosstab(sentence_nan, sentence_type), '\\n') # looking to see where the missing data is"
      ],
      "metadata": {
        "id": "DZtVhC7P_h-o",
        "outputId": "9c9de8be-0f5b-436f-f320-1aea73aba3b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DZtVhC7P_h-o",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentenceTypeAllChargesAtConvictionInContactEvent     0     1    2     4    9\n",
            "ImposedSentenceAllChargeInContactEvent                                      \n",
            "False                                             8720  4299  914     0    0\n",
            "True                                                 0     0    0  8779  274 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = sentence.mask(sentence_type == 4, 0) # Replace sentence with 0 when sentence_type is 4 to make sure that those aren't counted as missing values\n",
        "sentence = sentence.mask(sentence_type == 9, np.nan) # Replace sentence with np.nan when sentence_type is 9, since that mean they're missing values\n",
        "\n",
        "sentence_nan = sentence.isnull() # Create a new missing dummy\n",
        "print(pd.crosstab(sentence_nan, sentence_type), '\\n')  # looking to see where the missing data is\n",
        "print(np.sum(sentence_nan),'\\n') # displaying the calculated sum of all of the missing values in sentence_nan"
      ],
      "metadata": {
        "id": "_qPYaBEMAyod",
        "outputId": "c8a2bd96-7679-424f-f411-1e9f2b31f028",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "_qPYaBEMAyod",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentenceTypeAllChargesAtConvictionInContactEvent     0     1    2     4    9\n",
            "ImposedSentenceAllChargeInContactEvent                                      \n",
            "False                                             8720  4299  914  8779    0\n",
            "True                                                 0     0    0     0  274 \n",
            "\n",
            "274 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jdf['ImposedSentenceAllChargeInContactEvent'] = sentence # Replace data with cleaned version\n",
        "del sentence, sentence_type # Delete temporary sentence/sentence_type variables"
      ],
      "metadata": {
        "id": "lRtA3Yi8BltO"
      },
      "id": "lRtA3Yi8BltO",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5",
      "metadata": {
        "id": "649494cd-cfd6-4f80-992a-9994fc19e1d5"
      },
      "source": [
        "**Q3.** Many important datasets contain a race variable, typically limited to a handful of values often including Black, White, Asian, Latino, and Indigenous. This question looks at data gathering efforts on this variable by the U.S. Federal government.\n",
        "\n",
        "1. How did the most recent US Census gather data on race?\n",
        "2. Why do we gather these data? What role do these kinds of data play in politics and society? Why does data quality matter?\n",
        "3. Please provide a constructive criticism of how the Census was conducted: What was done well? What do you think was missing? How should future large scale surveys be adjusted to best reflect the diversity of the population? Could some of the Census' good practices be adopted more widely to gather richer and more useful data?\n",
        "4. How did the Census gather data on sex and gender? Please provide a similar constructive criticism of their practices.\n",
        "5. When it comes to cleaning data, what concerns do you have about protected characteristics like sex, gender, sexual identity, or race? What challenges can you imagine arising when there are missing values? What good or bad practices might people adopt, and why?\n",
        "6. Suppose someone invented an algorithm to impute values for protected characteristics like race, gender, sex, or sexuality. What kinds of concerns would you have?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}